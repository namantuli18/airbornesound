# -*- coding: utf-8 -*-
"""semi-supervised-6db-fan-2916ff.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tzEx2oNftaYc8pOPTsU6IkfT3KByHiS3
"""

import tensorflow as tf

import tensorflow_hub as hub

import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
import librosa

# Load the model.

vggmodel = hub.load('https://tfhub.dev/google/vggish/1')

def embedding_from_fn(fn):

    x, sr = librosa.load(fn,sr=None)

    x_16k = librosa.resample(x,sr,16000) #resample to 16KHz

    embedding = np.array(vggmodel(x_16k))

    return embedding

import vggish_input
import vggish_slim
import vggish_postprocess
import vggish_params
import mel_features

pproc = vggish_postprocess.Postprocessor("./vggish_pca_params.npz")

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

tf.Graph().as_default()
sess = tf.Session()

PCA_PARAMS = 'vggish_pca_params.npz'
CHECKPOINT = 'vggish_model.ckpt'

vggish_slim.define_vggish_slim(training=False)
vggish_slim.load_vggish_slim_checkpoint(sess, CHECKPOINT)
features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)
embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)

# new_features.to_csv("master-db.csv",index=False)

mfcc_batch=[]
postprocessed_batch=[]
file_paths=[]
classes=[]
i=0
for files in os.listdir("../input"):
    for subfiles in os.listdir(os.path.join("../input",files)):
        for subd in os.listdir(os.path.join("../input",files,subfiles)):
            for subc in os.listdir(os.path.join("../input",files,subfiles,subd)):
                for subb in os.listdir(os.path.join("../input",files,subfiles,subd,subc)):
                    path=os.path.join("../input",files,subfiles,subd,subc,subb)
                    #print(subc)
                    classes.append(subfiles+"_"+subc)
#                     print(subfiles+"_"+subc)
    # load the audio files
                    #print(subc)
                    data, sample_rate = librosa.load(path)
                    #print(sample_rate)
                    # compute the mfccs
                    mfccs = librosa.feature.mfcc(y=data, sr=sample_rate).T
                    mfcc_batch.append(mfccs)
                    example = vggish_input.wavfile_to_examples(path)
                    file_paths.append(path)
                    if example.size:
                        # get embedding
                        [embedding] = sess.run([embedding_tensor], feed_dict={features_tensor: example})
                        # get pca of embedding
                        pca = pproc.postprocess(embedding)
                    else:
                        pca = None
                    postprocessed_batch.append(pca)
                    i+=1
                    if i%1000==0:
                        print(f"{i} done")

new_features = pd.DataFrame({
    'embedding': postprocessed_batch, 
    'mfcc': mfcc_batch,
    # isolate the filename
    'files': file_paths,
    'classID' : classes
})
new_features.head()

df=new_features

#df.iloc[0]['mfcc'].shape

print('before dropna:', len(df))
df.dropna(inplace=True)
len(df)

df['embedding'].apply(lambda x: x.shape if x is not None else x).unique()

df['mfcc'].apply(lambda x: x.shape if x is not None else x).unique()

def aggregate_features(x, nmoments=1, moment0=1):
    '''Convert variable length numpy arrays to constant length vectors of summary statistics.'''
    mean = x.mean(axis=0)
    moments = [
        moment(x, moment=i, axis=0)
        for i in range(moment0, nmoments + moment0)
    ]
    return np.concatenate([mean] + moments)#

from scipy.stats import moment
df['embedding'] = df['embedding'].apply(aggregate_features)
df['mfcc'] = df['mfcc'].apply(aggregate_features)

df['embedding'].apply(lambda x: x.shape).unique()

# from sklearn.preprocessing import LabelEncoder
# l=LabelEncoder()
# df['classID']=np.nan
# for count,rows in enumerate(df['files']):
#     df['classID'][count]=df['files'][count].split("/")[3]

df['mfcc'].apply(lambda x: x.shape).unique()

from sklearn import preprocessing
  
# label_encoder object knows how to understand word labels.
label_encoder = preprocessing.LabelEncoder()
  
# Encode labels in column 'species'.
df['classID']= label_encoder.fit_transform(df['classID'])

X_vggish = np.vstack(df['embedding'].values)
X_mfcc = np.vstack(df['mfcc'].values)
Y = df['classID'].values
X_vggish.shape, X_mfcc.shape, Y.shape

from sklearn.manifold import TSNE

df['classID'].unique()

os.mkdir("plots")



classes=df['classID'].unique()

tsne_vggish = TSNE(2)
U_vggish = tsne_vggish.fit_transform(X_vggish)
import matplotlib.pyplot as plt
for i, cls in enumerate(classes):
    plt.scatter(U_vggish[Y==i,0], U_vggish[Y==i,1], label=cls, alpha=0.3, edgecolors=None)
plt.title('t-SNE Dimensionality Reduction of VGGish Embeddings')
plt.xticks([])
plt.yticks([])
plt.legend();

tsne_mfcc = TSNE(2)
U_mfcc = tsne_mfcc.fit_transform(X_mfcc)
for i, cls in enumerate(classes):
    plt.scatter(U_vggish[Y==i,0], U_vggish[Y==i,1], label=cls, alpha=0.3, edgecolors=None)
plt.title('t-SNE Dimensionality Reduction of Mfccish Embeddings')
plt.xticks([])
plt.yticks([])
plt.legend();

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
for i, cls in enumerate(classes):
    plt.scatter(U_vggish[Y==i,0], U_vggish[Y==i,1], label=cls, alpha=0.7, s=7)
plt.title('t-SNE Dimensionality Reduction of VGGish Embeddings')
plt.xticks([])
plt.yticks([])

plt.subplot(1, 2, 2)

for i, cls in enumerate(classes):
    plt.scatter(U_mfcc[Y==i,0], U_mfcc[Y==i,1], label=cls, alpha=0.7, s=7)
plt.title('t-SNE Dimensionality Reduction of MFCCs')
plt.xticks([])
plt.yticks([])
plt.legend(bbox_to_anchor=(0.066, 1))
plt.savefig('tsne_results.png');

# this isn't totally what I expected. Not sure if we'll do anything with this after all
plt.plot(label_distributions, np.mean(to0_1(results_vgg_test), axis=1), label='VGGish Semi-Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_mfcc_test), axis=1), label='MFCC Semi-Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_vgg_sup_test), axis=1), label='VGGish Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_mfcc_sup_test), axis=1), label='MFCC Supervised')
plt.title('Cumulative Test Accuracy')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('Proportion of Best Accuracy')
plt.legend()
plt.savefig('plots/cumulative-test-accuracy.png');

# this isn't totally what I expected. Not sure if we'll do anything with this after all
plt.plot(label_distributions, np.mean(to0_1(results_vgg_test), axis=1), label='VGGish Semi-Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_mfcc_test), axis=1), label='MFCC Semi-Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_vgg_sup_test), axis=1), label='VGGish Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_mfcc_sup_test), axis=1), label='MFCC Supervised')
plt.title('Cumulative Test Accuracy')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('Proportion of Best Accuracy')
plt.legend()
plt.savefig('plots/cumulative-test-accuracy.png');

import time
# from sklearn.svm import SVC
# from sklearn.mixture import GaussianMixture
# from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
# from sklearn.neural_network import MLPClassifier
# from sklearn.linear_model import LogisticRegression
# from sklearn.semi_supervised import LabelSpreading, LabelPropagation
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import GridSearchCV
print('Random Forest Grid Search Parameters:')
parameters = {
    'n_estimators': [5, 10, 20, 50, 100, 400],
    'max_depth': [20],
    'min_samples_split': [4]
}

X_vggish_subset, _, X_mfcc_subset, _, Y_subset, _ = train_test_split(X_vggish, X_mfcc, Y, train_size=0.3)
gs_vggish = GridSearchCV(RandomForestClassifier(), parameters).fit(X_vggish_subset, Y_subset)
gs_mfcc = GridSearchCV(RandomForestClassifier(), parameters).fit(X_mfcc_subset, Y_subset)
print('VGGish: ', gs_vggish.best_score_, gs_vggish.best_params_)
print('MFCCs: ', gs_mfcc.best_score_, gs_mfcc.best_params_)

class EM(RandomForestClassifier):
#     def __init__(self, priors=None): #C=0.4, kernel='linear', 
#         super(EM, self).__init__(priors=None)# , probability=True
        
    def fit(self, X, y, X_test, y_test, confidence=0.5, niters=50, tol=None, verbose=False, miniter=2, *a, **kw):
        parent = super(EM, self)
        
        # identify all unlabeled samples
        unlabeled = np.isnan(y)
        n_classes = len(np.unique(np.hstack([y[~unlabeled], y_test])))
        
        # perform initial fit using only labeled data
        parent.fit(X[~unlabeled], y[~unlabeled])
        
        # break out if there's no unlabeled data cuz we're done
        if not unlabeled.sum():
            return self
                
        # we need to create a row for each possible class for the unlabeled data
        X_expanded = np.concatenate(
            [X[~unlabeled]] + [X[unlabeled]]*n_classes
        )
        # labeled [y0, y1, ...], + unlabeled [0,0,0,...,1,1,1,...,n_classes-1,n_classes-1,...]
        y_expanded = np.hstack(
            [y[~unlabeled]] + list(np.c_[ [np.arange(n_classes)]*len(y[unlabeled]) ].T.ravel())
        )
        
        unlabeled_expanded = np.arange(len(y_expanded)) >= len(y[~unlabeled])
        weights = np.ones(len(y_expanded))
        
        # perform EM
        i = 0
        acc_test_prev = 0
        acc_test = (tol or 0) + 1 # init above tolerance
        while i < niters and (not tol or acc_test - acc_test_prev > tol or i < miniter):
            i += 1

            # update the weights based on prediction probabilities
            prob2 = self.predict_proba(X[unlabeled])
            prob = prob2.T.ravel()
            weights[unlabeled_expanded] = prob
            weights[weights < confidence] = 0

            # refit model based on updated weights
            parent.fit(X_expanded, y_expanded, sample_weight=weights) # refits the classifier
            
            # calculate accuracy
            acc_test_prev = acc_test
            acc_train = (self.predict(X) == y).mean()
            acc_test = (self.predict(X_test) == y_test).mean()
            
            if verbose:
                print('** Iteration {} ({}s):'.format(i, time.time() - t))
                print('In-sample Accuracy: {:.2%}'.format(acc_train))
                print('Out-of-sample Accuracy: {:.2%}'.format(acc_test))
                print()
        
        return self

def get_model_stats(model, X_train, y_train, X_test, y_test, em_iters=100):
    return dict(
        model=model,
        train_accuracy=(model.predict(X_train) == y_train).astype(float).mean(),
        test_accuracy=(model.predict(X_test) == y_test).astype(float).mean()
    )

def idxs2mask(length, idxs):
    # convert array of index values to a boolean mask
    unlabeled = np.zeros(length).astype(bool)
    unlabeled[idxs] = True
    return unlabeled

def results_to_np(results, features='vggish', train_test='test'):
    '''Converts results into numpy array
    Arguments:
        label_dist (float): the proportion label distribution (see: label_distributions)
        features (str): can be - vggish|mfcc|vggish_sup|mfcc_sup
        train_test (str): can be - train|test
    Returns:
        np.array of size (len(label_distributions), iters_per_dist)
    '''
    return np.array([
        [
            r[features][train_test + '_accuracy'] 
            for r in results[label_dist]
        ] for label_dist in sorted(results.keys())
    ])

def train_models(X_vggish, X_mfcc, y, label_dist, em_iters=100, tol=0.00001, confidence=0.5):
    # train/test split
    i_train, i_test, y_train, y_test = train_test_split(np.arange(len(y)), y, test_size=0.33)
    X_vggish_train, X_vggish_test = X_vggish[i_train], X_vggish[i_test]
    X_mfcc_train, X_mfcc_test = X_mfcc[i_train], X_mfcc[i_test]
    
    
    # normalize between -1 and 1
    scaler_vggish = StandardScaler().fit(X_vggish_train)
    X_vggish_train = scaler_vggish.transform(X_vggish_train)
    X_vggish_test = scaler_vggish.transform(X_vggish_test)
    
    scaler_mfcc = StandardScaler().fit(X_mfcc_train)
    X_mfcc_train = scaler_mfcc.transform(X_mfcc_train)
    X_mfcc_test = scaler_mfcc.transform(X_mfcc_test)
    
    y_train_partial = y_train.copy().astype(float)

    # get mask to select which labels to remove
    if label_dist >= 1: # special case where there's no unlabeled data. train_test_split would throw an error
        unlabeled, labeled = np.zeros(len(y_train)).astype(bool), np.ones(len(y_train)).astype(bool)
    else:
        unlabeled, labeled = train_test_split(np.arange(len(y_train)), stratify=y_train, test_size=label_dist)
        unlabeled = idxs2mask(len(y_train), unlabeled)
        labeled = idxs2mask(len(y_train), labeled)
    
    # remove labels
    y_train_partial[unlabeled] = None

    
#     # train model - use gridsearch when you get a chance probability=True, kernel='linear'
    model_vggish = EM().fit(X_vggish_train, y_train_partial, 
                            X_vggish_test, y_test, niters=em_iters, tol=tol, confidence=confidence)
    model_mfcc = EM().fit(X_mfcc_train, y_train_partial, 
                          X_mfcc_test, y_test, niters=em_iters, tol=tol, confidence=confidence)
    
    # run normal supervised learning (dropping the unlabeled data)
    model_vggish_sup = EM().fit(X_vggish_train[labeled], y_train_partial[labeled], 
                                X_vggish_test, y_test, niters=em_iters, tol=tol, confidence=confidence)
    model_mfcc_sup = EM().fit(X_mfcc_train[labeled], y_train_partial[labeled], 
                              X_mfcc_test, y_test, niters=em_iters, tol=tol, confidence=confidence)
#     model_vggish = LabelPropagation(kernel='knn').fit(X_vggish_train, y_train_partial)
#     model_mfcc = LabelPropagation(kernel='knn').fit(X_mfcc_train, y_train_partial)
    
    # return stats for each model
    return dict(
        # return the model stats
        vggish=get_model_stats(model_vggish, X_vggish_train, y_train, X_vggish_test, y_test),
        mfcc=get_model_stats(model_mfcc, X_mfcc_train, y_train, X_mfcc_test, y_test),
        vggish_sup=get_model_stats(model_vggish_sup, X_vggish_train, y_train, X_vggish_test, y_test),
        mfcc_sup=get_model_stats(model_mfcc_sup, X_mfcc_train, y_train, X_mfcc_test, y_test),
        
        # save the feature scalers used
        scaler_vggish=scaler_vggish,
        scaler_mfcc=scaler_mfcc
    )


train_models(X_vggish, X_mfcc, Y, 1, em_iters=5)

label_distributions = [0.01, 0.03, 0.05, 0.08, 0.1, 0.3, 0.5, 0.7, 1]

def calc_label_distributions(confidence=0.5, iters_per_dist=10):
    t = time.time()
    results = {}

    # proportion of training samples with labels
    for label_dist in label_distributions:
        ti = time.time()
        print(label_dist)
        results[label_dist] = []
        for i in np.arange(iters_per_dist):
            print(i, end=' ')
            results[label_dist].append(train_models(X_vggish, X_mfcc, Y, label_dist, em_iters=5, confidence=confidence))#, tol=0.01
        print(time.time() - ti, max([r['vggish']['test_accuracy'] for r in results[label_dist]]))
        ti = time.time()
    print('total time for {}*{} iterations'.format(len(label_distributions), iters_per_dist), time.time() - t)     
    return results

results = calc_label_distributions(iters_per_dist=30)

# row=label_distribution, column=iteration
print('Test Results for VGGish:')
results_to_np(results)

results_vgg_test = results_to_np(results, features='vggish')
results_mfcc_test = results_to_np(results, features='mfcc')
results_vgg_sup_test = results_to_np(results, features='vggish_sup')
results_mfcc_sup_test = results_to_np(results, features='mfcc_sup')

print('Average VGGish Results')
pd.Series(results_vgg_test.mean(1), index=label_distributions)

print(results_to_np(results, features='mfcc', train_test='test'))
print('')
print(results_to_np(results, features='mfcc', train_test='train'))

# png plot size
plt.rcParams['figure.figsize'] = 8, 5
# notebook plot size
# plt.rcParams['figure.figsize'] = 15, 8

plt.plot(label_distributions, results_vgg_test.mean(1), label='VGGish Semi-Supervised')
plt.plot(label_distributions, results_mfcc_test.mean(1), label='MFCC Semi-Supervised')
plt.plot(label_distributions, results_vgg_sup_test.mean(1), label='VGGish Supervised')
plt.plot(label_distributions, results_mfcc_sup_test.mean(1), label='MFCC Supervised')
plt.title('Average Test Accuracy vs. Proportion of Labeled Data in Training Set')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('Test Accuracy')
# plt.ylim([0, None])
plt.legend(loc='lower right')
plt.savefig('plots/test-accuracy.png');

results_mfcc_test.shape, len(label_distributions)

plt.boxplot(results_vgg_test.T, positions=label_distributions)
plt.boxplot(results_mfcc_test.T, positions=label_distributions)
plt.legend();

def ci_plot(label_distributions, Y, label=None):
    mean = np.mean(Y, axis=1)
    std = np.std(Y, axis=1)
    plt.fill_between(label_distributions, mean - 2*std, mean + 2*std, alpha=0.2)
    plt.plot(label_distributions, mean, label=label)

ci_plot(label_distributions, results_vgg_test, 'VGGish Semi-Supervised')
ci_plot(label_distributions, results_mfcc_test, 'MFCC Semi-Supervised')
ci_plot(label_distributions, results_vgg_sup_test, 'VGGish Supervised')
ci_plot(label_distributions, results_mfcc_sup_test, 'MFCC Supervised')
plt.title('Test Accuracy $\pm 2\sigma$ over Varying Proportions of Labeled Data')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('Test Accuracy')
plt.ylim([0.3, None])
plt.legend(loc='lower right')
plt.savefig('plots/test-accuracy-ci.png');

from scipy import stats

tuple(stats.ks_2samp(results_vgg_test[0], results_vgg_sup_test[0]))

def get_ks_results(result1, result2):
    return pd.DataFrame([
        tuple(stats.ks_2samp(x1, x2))
        for x1, x2 in zip(result1, result2)
    ], index=label_distributions, columns=['KS Statistic', 'P Value'])

ks_vggish = get_ks_results(results_vgg_test, results_vgg_sup_test)
ks_vggish

ks_mfcc = get_ks_results(results_mfcc_test, results_mfcc_sup_test)
ks_mfcc

# critical values: http://www.mathematik.uni-kl.de/~schwaar/Exercises/Tabellen/table_kolmogorov.pdf
ks_critical_value = 0.490 # for n=10

plt.figure(figsize=(15, 3))

plt.subplot(1, 2, 1)
ks_vggish['KS Statistic'].plot()
plt.plot([label_distributions[0], label_distributions[-1]], [ks_critical_value, ks_critical_value], 'r', label='Critical Value')
plt.fill_between(label_distributions, ks_vggish['KS Statistic'], [ks_critical_value]*len(ks_stat_vggish), where=ks_vggish['KS Statistic']<ks_critical_value, facecolor='red', interpolate=True, alpha=0.2)
plt.fill_between(label_distributions, ks_vggish['KS Statistic'], [ks_critical_value]*len(ks_stat_vggish), where=ks_vggish['KS Statistic']>ks_critical_value, facecolor='green', interpolate=True, alpha=0.2)
plt.title('KS Test between VGGish Supervised and Semi-Supervised')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('KS Statistic')
plt.ylim([0, None])
plt.legend()

plt.subplot(1, 2, 2)

ks_mfcc['KS Statistic'].plot()
plt.plot([label_distributions[0], label_distributions[-1]], [ks_critical_value, ks_critical_value], 'r', label='Critical Value')
plt.fill_between(label_distributions, ks_mfcc['KS Statistic'], [ks_critical_value]*len(ks_vggish), where=ks_mfcc['KS Statistic']<ks_critical_value, facecolor='red', interpolate=True, alpha=0.2)
plt.fill_between(label_distributions, ks_mfcc['KS Statistic'], [ks_critical_value]*len(ks_vggish), where=ks_mfcc['KS Statistic']>ks_critical_value, facecolor='green', interpolate=True, alpha=0.2)
plt.title('KS Test between MFCC Supervised and Semi-Supervised')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('KS Statistic')
plt.ylim([0, None])
plt.legend()
plt.savefig('plots/ks-test.png');

def to0_1(X):
    return (X - X.mean(1).min()) / (X.mean(1).max() - X.mean(1).min())

# this isn't totally what I expected. Not sure if we'll do anything with this after all
plt.plot(label_distributions, np.mean(to0_1(results_vgg_test), axis=1), label='VGGish Semi-Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_mfcc_test), axis=1), label='MFCC Semi-Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_vgg_sup_test), axis=1), label='VGGish Supervised')
plt.plot(label_distributions, np.mean(to0_1(results_mfcc_sup_test), axis=1), label='MFCC Supervised')
plt.title('Cumulative Test Accuracy')
plt.xlabel('Proportion of Labeled Data')
plt.ylabel('Proportion of Best Accuracy')
plt.legend()
plt.savefig('plots/cumulative-test-accuracy.png');