# -*- coding: utf-8 -*-
"""visualize_data_distribution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1azetuOJibrovotXKaVLrAEyTYkUzxVwy
"""

import tensorflow as tf

import tensorflow_hub as hub

import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
import librosa

# Load the model.

vggmodel = hub.load('https://tfhub.dev/google/vggish/1')

def embedding_from_fn(fn):

    x, sr = librosa.load(fn,sr=None)

    x_16k = librosa.resample(x,sr,16000) #resample to 16KHz

    embedding = np.array(vggmodel(x_16k))

    return embedding

import vggish_input
import vggish_slim
import vggish_postprocess
import vggish_params
import mel_features

pproc = vggish_postprocess.Postprocessor("./vggish_pca_params.npz")

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

tf.Graph().as_default()
sess = tf.Session()

PCA_PARAMS = 'vggish_pca_params.npz'
CHECKPOINT = 'vggish_model.ckpt'

vggish_slim.define_vggish_slim(training=False)
vggish_slim.load_vggish_slim_checkpoint(sess, CHECKPOINT)
features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)
embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)

# new_features.to_csv("master-db.csv",index=False)

mfcc_batch=[]
postprocessed_batch=[]
file_paths=[]
classes=[]
i=0
for files in os.listdir("../input"):
    for subfiles in os.listdir(os.path.join("../input",files)):
        for subd in os.listdir(os.path.join("../input",files,subfiles)):
            for subc in os.listdir(os.path.join("../input",files,subfiles,subd)):
                for subb in os.listdir(os.path.join("../input",files,subfiles,subd,subc)):
                    path=os.path.join("../input",files,subfiles,subd,subc,subb)
                    #print(subc)
                    classes.append(subfiles+"_"+subc)
#                     print(subfiles+"_"+subc)
    # load the audio files
                    #print(subc)
                    data, sample_rate = librosa.load(path)
                    #print(sample_rate)
                    # compute the mfccs
                    mfccs = librosa.feature.mfcc(y=data, sr=sample_rate).T
                    mfcc_batch.append(mfccs)
                    example = vggish_input.wavfile_to_examples(path)
                    file_paths.append(path)
                    if example.size:
                        # get embedding
                        [embedding] = sess.run([embedding_tensor], feed_dict={features_tensor: example})
                        # get pca of embedding
                        pca = pproc.postprocess(embedding)
                    else:
                        pca = None
                    postprocessed_batch.append(pca)
                    i+=1
                    if i%1000==0:
                        print(f"{i} done")

new_features = pd.DataFrame({
    'embedding': postprocessed_batch, 
    'mfcc': mfcc_batch,
    # isolate the filename
    'files': file_paths,
    'classID' : classes
})
new_features.head()

df=new_features

df.iloc[0]['mfcc'].shape

print('before dropna:', len(df))
df.dropna(inplace=True)
len(df)

df['embedding'].apply(lambda x: x.shape if x is not None else x).unique()

df['mfcc'].apply(lambda x: x.shape if x is not None else x).unique()

def aggregate_features(x, nmoments=1, moment0=1):
    '''Convert variable length numpy arrays to constant length vectors of summary statistics.'''
    mean = x.mean(axis=0)
    moments = [
        moment(x, moment=i, axis=0)
        for i in range(moment0, nmoments + moment0)
    ]
    return np.concatenate([mean] + moments)#

from scipy.stats import moment
df['embedding'] = df['embedding'].apply(aggregate_features)
df['mfcc'] = df['mfcc'].apply(aggregate_features)

df['embedding'].apply(lambda x: x.shape).unique()

# from sklearn.preprocessing import LabelEncoder
# l=LabelEncoder()
# df['classID']=np.nan
# for count,rows in enumerate(df['files']):
#     df['classID'][count]=df['files'][count].split("/")[3]

df['mfcc'].apply(lambda x: x.shape).unique()

from sklearn import preprocessing
  
# label_encoder object knows how to understand word labels.
label_encoder = preprocessing.LabelEncoder()
  
# Encode labels in column 'species'.
df['classID']= label_encoder.fit_transform(df['classID'])

X_vggish = np.vstack(df['embedding'].values)
X_mfcc = np.vstack(df['mfcc'].values)
Y = df['classID'].values
X_vggish.shape, X_mfcc.shape, Y.shape

from sklearn.manifold import TSNE

df['classID'].unique()





classes=df['classID'].unique()

tsne_vggish = TSNE(2)
U_vggish = tsne_vggish.fit_transform(X_vggish)
import matplotlib.pyplot as plt
for i, cls in enumerate(classes):
    plt.scatter(U_vggish[Y==i,0], U_vggish[Y==i,1], label=cls, alpha=0.3, edgecolors=None)
plt.title('t-SNE Dimensionality Reduction of VGGish Embeddings')
plt.xticks([])
plt.yticks([])
plt.legend();

tsne_mfcc = TSNE(2)
U_mfcc = tsne_mfcc.fit_transform(X_mfcc)
for i, cls in enumerate(classes):
    plt.scatter(U_vggish[Y==i,0], U_vggish[Y==i,1], label=cls, alpha=0.3, edgecolors=None)
plt.title('t-SNE Dimensionality Reduction of Mfccish Embeddings')
plt.xticks([])
plt.yticks([])
plt.legend();

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
for i, cls in enumerate(classes):
    plt.scatter(U_vggish[Y==i,0], U_vggish[Y==i,1], label=cls, alpha=0.7, s=7)
plt.title('t-SNE Dimensionality Reduction of VGGish Embeddings')
plt.xticks([])
plt.yticks([])

plt.subplot(1, 2, 2)

for i, cls in enumerate(classes):
    plt.scatter(U_mfcc[Y==i,0], U_mfcc[Y==i,1], label=cls, alpha=0.7, s=7)
plt.title('t-SNE Dimensionality Reduction of MFCCs')
plt.xticks([])
plt.yticks([])
plt.legend(bbox_to_anchor=(0.066, 1))
plt.savefig('tsne_results.png');